version: "3"
services:
  tts:
    container_name: streamer-sales-tts-server
    build:
      context: ./
      dockerfile: ./docker/Dockerfile
    image: streamer-sales:v0.8.0
    volumes:
      - ./weights:/workspace/Streamer-Sales/weights
      - ./work_dirs:/workspace/Streamer-Sales/work_dirs
    ports:
      - "8001:8001"
    networks:
      - streamer-sales-network
    environment:
      USING_DOCKER_COMPOSE: "true"
      HF_ENDPOINT: "https://hf-mirror.com"
      LANG: "en_US.UTF-8"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0' ]
              capabilities: [ gpu ]
    command:
      - /bin/bash
      - -c
      - |
        nvidia-smi
        uvicorn server.tts.tts_server:app --host 0.0.0.0 --port 8001
    restart: always

  digital_human:
    container_name: streamer-sales-digital-human-server
    build:
      context: ./
      dockerfile: ./docker/Dockerfile
    image: streamer-sales:v0.8.0
    volumes:
      - ./weights:/workspace/Streamer-Sales/weights
      - ./work_dirs:/workspace/Streamer-Sales/work_dirs
    ports:
      - "8002:8002"
    networks:
      - streamer-sales-network
    environment:
      USING_DOCKER_COMPOSE: "true"
      HF_ENDPOINT: "https://hf-mirror.com"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '1' ]
              capabilities: [ gpu ]
    command:
      - /bin/bash
      - -c
      - |
        nvidia-smi
        uvicorn server.digital_human.digital_human_server:app --host 0.0.0.0 --port 8002
    restart: always

  asr:
    container_name: streamer-sales-asr-server
    build:
      context: ./
      dockerfile: ./docker/Dockerfile
    image: streamer-sales:v0.8.0
    volumes:
      - ./weights:/workspace/Streamer-Sales/weights
      - ./work_dirs:/workspace/Streamer-Sales/work_dirs
    ports:
      - "8003:8003"
    networks:
      - streamer-sales-network
    environment:
      USING_DOCKER_COMPOSE: "true"
      HF_ENDPOINT: "https://hf-mirror.com"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '1' ]
              capabilities: [ gpu ]
    command:
      - /bin/bash
      - -c
      - |
        nvidia-smi
        uvicorn server.asr.asr_server:app --host 0.0.0.0 --port 8003
    restart: always

  llm:
    container_name: streamer-sales-llm-server
    build:
      context: ./
      dockerfile: ./docker/Dockerfile
    image: streamer-sales:v0.8.0
    volumes:
      - ./weights:/workspace/Streamer-Sales/weights
      - ./work_dirs:/workspace/Streamer-Sales/work_dirs
    ports:
      - "23333:23333"
    networks:
      - streamer-sales-network
    environment:
      USING_DOCKER_COMPOSE: "true"
      LMDEPLOY_USE_MODELSCOPE: "True"
      MODELSCOPE_CACHE: "./weights/llm_weights"
      HF_ENDPOINT: "https://hf-mirror.com"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '3' ]
              capabilities: [ gpu ]
    command:
      - /bin/bash
      - -c
      - |
        nvidia-smi
        lmdeploy serve api_server HinGwenWoong/streamer-sales-lelemiao-7b-4bit \
                      --server-port 23333 \
                      --model-name internlm2 \
                      --session-len 32768 \
                      --cache-max-entry-count 0.1 \
                      --model-format awq
    restart: always

  base:
    container_name: streamer-sales-base-server
    build:
      context: ./
      dockerfile: ./docker/Dockerfile
    image: streamer-sales:v0.8.0
    volumes:
      - ./weights:/workspace/Streamer-Sales/weights
      - ./work_dirs:/workspace/Streamer-Sales/work_dirs
    ports:
      - "8000:8000"
    networks:
      - streamer-sales-network
    depends_on:
      - llm
      - tts
      - digital_human
      - asr
    environment:
      USING_DOCKER_COMPOSE: "true"
      HF_ENDPOINT: "https://hf-mirror.com"

      # Agent Key (如果没有请忽略)
      # DELIVERY_TIME_API_KEY: "${快递 EBusinessID},${快递 api_key}"
      # WEATHER_API_KEY: "${天气 API key}"

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '2' ]
              capabilities: [ gpu ]
    command:
      - /bin/bash
      - -c
      - |
        nvidia-smi
        sleep 60
        uvicorn server.base.base_server:app --host 0.0.0.0 --port 8000
    restart: always

  frontend:
    container_name: streamer-sales-frontend
    build:
      context: ./
      dockerfile: ./docker/Dockerfile
    image: streamer-sales:v0.8.0
    volumes:
      - ./weights:/workspace/Streamer-Sales/weights
      - ./work_dirs:/workspace/Streamer-Sales/work_dirs
    ports:
      - "7860:7860"
    networks:
      - streamer-sales-network
    environment:
      USING_DOCKER_COMPOSE: "true"
    depends_on:
      - base
    command:
      - /bin/bash
      - -c
      - |
        sleep 90
        streamlit run app.py --server.address=0.0.0.0 --server.port 7860
    restart: always

networks:
  streamer-sales-network:
